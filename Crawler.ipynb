{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a short and simple webcrawler for navigating over public domain websites and, if necessary, downloading pdf archives. It is useful for downloading articles about certain topics from public repositories. \n",
    "The program was created for 2 specific websites, so some changes are necessary when applied for other domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\duhju\\\\Desktop\\\\Crawler'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date, datetime\n",
    "import bs4 as bs\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import schedule\n",
    "## Need to install library and .exe file to be able to download pdf's    \n",
    "## https://github.com/wkhtmltopdf/wkhtmltopdf/releases/download/0.12.5/wkhtmltox-0.12.5-1.mxe-cross-win64.7z\n",
    "import pdfkit\n",
    "\n",
    "working_dir = ''\n",
    "os.chdir('')\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--disable-notifications')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--verbose')\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--disable-extensions')\n",
    "options.add_argument('--incognito')\n",
    "options.add_experimental_option('prefs',  {\n",
    "    \"download.default_directory\": working_dir,\n",
    "    \"download.prompt_for_download\": False,\n",
    "    \"download.directory_upgrade\": True,\n",
    "    \"plugins.always_open_pdf_externally\": True,\n",
    "    \"safebrowsing.enabled\": True,\n",
    "    'safebrowsing.disable_download_protection': False,\n",
    "})\n",
    "driver=webdriver.Chrome(options=options)\n",
    "driver.command_executor._commands[\"send_command\"] = (\"POST\", '/session/$sessionId/chromium/send_command')\n",
    "params = {'cmd': 'Page.setDownloadBehavior', 'params': {'behavior': 'allow', 'downloadPath': working_dir}}\n",
    "command_result = driver.execute(\"send_command\", params)\n",
    "\n",
    "mapping = {\n",
    "    'janeiro' : '01',\n",
    "    'fevereiro' : '02',\n",
    "    'marÃ§o' : '03',\n",
    "    'abril' : '04',\n",
    "    'maio' : '05',\n",
    "    'junho' : '06',\n",
    "    'julho' : '07',\n",
    "    'agosto' : '08',\n",
    "    'setembro' : '09', \n",
    "    'outubro' : '10',\n",
    "    'novembro' : '11',\n",
    "    'dezembro' : '12'\n",
    "}\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def website_1(driver, url, date):    \n",
    "    driver.get(url)\n",
    "    ##Set the period to request the documents\n",
    "    datepicker = driver.find_element_by_id(\"period\")\n",
    "    datepicker.click()\n",
    "    datepicker = driver.find_element_by_id(\"init_date\")\n",
    "    datepicker.click()\n",
    "    datepicker.clear()\n",
    "    datepicker.send_keys(date)\n",
    "    datepicker = driver.find_element_by_id(\"final_date\")\n",
    "    datepicker.click()\n",
    "    datepicker.clear()\n",
    "    datepicker.send_keys(date)\n",
    "    search = driver.find_element_by_id(\"searcj\")\n",
    "    search.click()\n",
    "    time.sleep(3)\n",
    "    ##Find the links for each document and download their pdf's\n",
    "    soup = bs.BeautifulSoup(driver.page_source, 'lxml')\n",
    "    for tr in soup.find_all('table')[-1].find_all('tr')[1:]:\n",
    "        driver.get('http://' + tr.find_all('a')[0].get('href'))\n",
    "        driver.find_element_by_id(\"lbtnPdf\").click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def website_2(driver, url, year, month, today):\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    try:\n",
    "        driver.get(url + year + '---' + month + '---')\n",
    "    except:\n",
    "        driver.get(url + '---' + year + '/' + month +'---')\n",
    "    time.sleep(3)\n",
    "    soup =  bs.BeautifulSoup(driver.page_source, 'lxml')\n",
    "    links = []\n",
    "    for tr in soup.find_all('table')[-1].find_all('tr')[1:3]:\n",
    "        last_date = tr.find('td').get_text().split('-')[0].strip().split(' de ')\n",
    "        if '/'.join([last_date[0], mapping[last_date[1]], last_date[2]]) == today:\n",
    "            links.extend([i.get('href') for i in tr.find_all('a', attrs={'href': re.compile(\"^http://\")})])\n",
    "    for link in links:\n",
    "        pdfkit.from_url(link, link.split('/')[-1].split('.')[0]+'.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(today):\n",
    "    try:\n",
    "        website_1('http://',\n",
    "                                  today.split('/')[2], today.split('/')[1], today)\n",
    "        website_2(driver, 'http://', today)\n",
    "        downloaded = True\n",
    "    else:\n",
    "        downloaded = False\n",
    "    return downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while __name__ == \"__main__\":\n",
    "    downloaded = False\n",
    "    today = str(date.today() + timedelta(days=1))\n",
    "    today = today.split('-')[2] + '/' + today.split('-')[1] + '/' + today.split('-')[0]\n",
    "    time_now = str(datetime.now()).split()[1]\n",
    "    if time_now >= \"23:59:00.000000\" and time_now < \"23:59:59.999999\":\n",
    "        while not(downloaded):\n",
    "            downloaded = main(today)\n",
    "            time.sleep(60)\n",
    "        time.sleep((23 - datetime.now().hour)*3600)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
